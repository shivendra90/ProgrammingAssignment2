# Using Cached Functions and Matrices to Perform Large Calculations

Performing large calculations through R can be cumbersome and if not speedier than other programming languages like C# or C++, similar to their system runtimes. In fact, R is somewhat rudimentary here, when it comes to system optimisations since its basically a language to carry out statistical or mathematical calculations. With that said, the creators of R never really had in mind the immense calculations its users might need to perform when its first versions in the 1980s and later in 90s came out. Its only in recent times that several techniques and built-in optimisations have been developed over the base structure for several large calculations to be performed as optimally as possible. The emergence of big data and faster, more powerful computing machines have resulted in even more data being generated on a daily basis. The data we have today is incomparable times that we might have had during the 1990s when the internet first became public.

Hence, considering such circumstances, certain specific operations for 'storing' valuable data and carrying out heavy duty operations on them become necessary. Of course, users have new and emerging technologies like Apache and Hadoop that allow for performing operations on datasets that go well into gigabytes or even terabytes. These technologies have their own learning curves and hence should be treated as different from the mainstream data analytics platforms like Python or R; however, they even have their own integrations into these languages.

Whatever the case maybe, efficient and optimised operation executing is one of the primary task for not just a data scientist but for any programmer in any language. Every coder should strive for developing user-friendly, user-readable and yet at the same time efficient, fast programme with as little code as possible. This eases off the burden on the CPU as well as take only the required resources that make the code efficient. For example, instead of using the for loop for reading a bunch of similar files, one can instead use commands from the apply family (like lapply) to build efficient programmes.

With limited resources, and absence of technologies like Apache and Hadoop, several developers code their own techniques of efficient execution and storage. The cachematrix.R shown in this repository is just one of the many ways one can use to develop clean and fast/efficient code. This is an exercise of the JHU data science specialisation for the R Programming class, and pertains to the second week's peer reviewed project to understand R's lexical scoping utility in more detail. The script contains annotations for every line and command to make every step understandable to the reviewer. Seeming complex at the first sight, the script basically tries to achieve a wrapper wherein the user can store large values with a much reduced load on the CPU and processing time and a wrapper for calculation purposes which when stored in the memory, achieves a similar operation as the above, but with the difference that the second wrapper swiftens the calculation time.
